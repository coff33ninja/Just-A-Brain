[
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "# noqa: E402\r\n    load_sensor_data",
        "importPath": "main",
        "description": "main",
        "isExtraImport": true,
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "load_image_text_pairs",
        "importPath": "main",
        "description": "main",
        "isExtraImport": true,
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "load_vision_data",
        "importPath": "main",
        "description": "main",
        "isExtraImport": true,
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "load_text_data",
        "importPath": "main",
        "description": "main",
        "isExtraImport": true,
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "BrainCoordinator",
        "importPath": "main",
        "description": "main",
        "isExtraImport": true,
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "DEFAULT_IMAGE_PATH",
        "importPath": "main",
        "description": "main",
        "isExtraImport": true,
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "TemporalLobeAI",
        "importPath": "temporal",
        "description": "temporal",
        "isExtraImport": true,
        "detail": "temporal",
        "documentation": {}
    },
    {
        "label": "TemporalLobeAI",
        "importPath": "temporal",
        "description": "temporal",
        "isExtraImport": true,
        "detail": "temporal",
        "documentation": {}
    },
    {
        "label": "CerebellumAI",
        "importPath": "cerebellum",
        "description": "cerebellum",
        "isExtraImport": true,
        "detail": "cerebellum",
        "documentation": {}
    },
    {
        "label": "CerebellumAI",
        "importPath": "cerebellum",
        "description": "cerebellum",
        "isExtraImport": true,
        "detail": "cerebellum",
        "documentation": {}
    },
    {
        "label": "LimbicSystemAI",
        "importPath": "limbic",
        "description": "limbic",
        "isExtraImport": true,
        "detail": "limbic",
        "documentation": {}
    },
    {
        "label": "LimbicSystemAI",
        "importPath": "limbic",
        "description": "limbic",
        "isExtraImport": true,
        "detail": "limbic",
        "documentation": {}
    },
    {
        "label": "OccipitalLobeAI",
        "importPath": "occipital",
        "description": "occipital",
        "isExtraImport": true,
        "detail": "occipital",
        "documentation": {}
    },
    {
        "label": "OccipitalLobeAI",
        "importPath": "occipital",
        "description": "occipital",
        "isExtraImport": true,
        "detail": "occipital",
        "documentation": {}
    },
    {
        "label": "FrontalLobeAI",
        "importPath": "frontal",
        "description": "frontal",
        "isExtraImport": true,
        "detail": "frontal",
        "documentation": {}
    },
    {
        "label": "FrontalLobeAI",
        "importPath": "frontal",
        "description": "frontal",
        "isExtraImport": true,
        "detail": "frontal",
        "documentation": {}
    },
    {
        "label": "ParietalLobeAI",
        "importPath": "parietal",
        "description": "parietal",
        "isExtraImport": true,
        "detail": "parietal",
        "documentation": {}
    },
    {
        "label": "ParietalLobeAI",
        "importPath": "parietal",
        "description": "parietal",
        "isExtraImport": true,
        "detail": "parietal",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Input",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Input",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Conv2D",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "MaxPooling2D",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Input",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "tensorflow.keras.optimizers",
        "description": "tensorflow.keras.optimizers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.optimizers",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "tensorflow.keras.optimizers",
        "description": "tensorflow.keras.optimizers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.optimizers",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "gradio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gradio",
        "description": "gradio",
        "detail": "gradio",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "TestDataLoading",
        "kind": 6,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "class TestDataLoading(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)\n        cls.vision_content = {\"image_paths\": [os.path.join(TEST_IMAGES_SUBDIR, \"img1.png\")]}\n        with open(TEST_VISION_FILE, 'w') as f:\n            json.dump(cls.vision_content, f)\n        cls.sensor_content = [[1.0, 2.0], [3.0, 4.0]]\n        with open(TEST_SENSOR_FILE, 'w') as f:\n            json.dump(cls.sensor_content, f)",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TestTemporalLobeAI",
        "kind": 6,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "class TestTemporalLobeAI(unittest.TestCase):\n    def setUp(self):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)\n        # Ensure clean state before AI initialization\n        if os.path.exists(TEST_TEMPORAL_MODEL_PATH):\n            os.remove(TEST_TEMPORAL_MODEL_PATH)\n        if os.path.exists(TEST_TEMPORAL_MEMORY_PATH):\n            os.remove(TEST_TEMPORAL_MEMORY_PATH)\n        self.ai = TemporalLobeAI(model_path=TEST_TEMPORAL_MODEL_PATH, memory_path=TEST_TEMPORAL_MEMORY_PATH)\n        self.ai._initialize_default_weights_biases()",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TestLimbicSystemAI",
        "kind": 6,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "class TestLimbicSystemAI(unittest.TestCase):\n    def setUp(self):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)\n        if os.path.exists(TEST_LIMBIC_MODEL_PATH):\n            os.remove(TEST_LIMBIC_MODEL_PATH)\n        self.ai = LimbicSystemAI(model_path=TEST_LIMBIC_MODEL_PATH)\n        self.ai.save_model()\n        self.sample_temporal_output = np.random.rand(self.ai.input_size).tolist()\n        self.sample_true_emotion = 1\n        self.sample_reward = 1.0",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TestOccipitalLobeAI",
        "kind": 6,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "class TestOccipitalLobeAI(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        os.makedirs(TEST_IMAGES_SUBDIR, exist_ok=True)\n        cls.img_size = (32, 32)\n        cls.test_img_path = os.path.join(TEST_IMAGES_SUBDIR, \"test_image.png\")\n        Image.new('L', cls.img_size, 255).save(cls.test_img_path)\n    @classmethod\n    def tearDownClass(cls):\n        if os.path.exists(TEST_IMAGES_SUBDIR):",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TestFrontalLobeAI",
        "kind": 6,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "class TestFrontalLobeAI(unittest.TestCase):\n    def setUp(self):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)\n        self.epsilon_path = (\n            TEST_FRONTAL_MODEL_PATH + \"_epsilon.json\"\n        )  # Consistent with typical save logic\n        if os.path.exists(TEST_FRONTAL_MODEL_PATH):\n            os.remove(TEST_FRONTAL_MODEL_PATH)\n        if os.path.exists(self.epsilon_path):\n            os.remove(self.epsilon_path)",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TestCerebellumAI",
        "kind": 6,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "class TestCerebellumAI(unittest.TestCase):\n    def setUp(self):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)\n        # Ensure clean state before AI initialization\n        if os.path.exists(TEST_CEREBELLUM_MODEL_PATH):\n            os.remove(TEST_CEREBELLUM_MODEL_PATH)\n        self.ai = CerebellumAI(model_path=TEST_CEREBELLUM_MODEL_PATH)\n        self.ai._initialize_default_weights_biases()\n        self.ai.save_model()\n        self.sample_sensor_data = np.random.rand(self.ai.input_size).tolist()",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TestParietalLobeAI",
        "kind": 6,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "class TestParietalLobeAI(unittest.TestCase):\n    def setUp(self):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)\n        # Ensure clean state before AI initialization\n        if os.path.exists(TEST_PARIETAL_MODEL_PATH):\n            os.remove(TEST_PARIETAL_MODEL_PATH)\n        self.ai = ParietalLobeAI(model_path=TEST_PARIETAL_MODEL_PATH)\n        self.ai._initialize_default_weights_biases()\n        self.ai.save_model()\n        self.sample_sensory_data = np.random.rand(self.ai.input_size).tolist() # input_size is 20",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "project_root",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n# Now, import project modules\nfrom main import ( # noqa: E402\n    load_sensor_data,\n    load_image_text_pairs,\n    load_vision_data,\n    load_text_data,\n)",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_DATA_DIR",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_DATA_DIR = \"data_test\"\nTEST_IMAGES_SUBDIR = os.path.join(TEST_DATA_DIR, \"images\") # Subdirectory for test images\n# Define paths for dummy data files within TEST_DATA_DIR\nTEST_VISION_FILE = os.path.join(TEST_DATA_DIR, \"test_vision.json\")\nTEST_SENSOR_FILE = os.path.join(TEST_DATA_DIR, \"test_sensors.json\")\nTEST_TEXT_FILE = os.path.join(TEST_DATA_DIR, \"test_text.json\")\nTEST_PAIRS_FILE = os.path.join(TEST_DATA_DIR, \"test_pairs.json\")\n# Define paths for AI model files within TEST_DATA_DIR\nTEST_TEMPORAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_model.json\")\nTEST_TEMPORAL_MEMORY_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_memory.json\")",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_IMAGES_SUBDIR",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_IMAGES_SUBDIR = os.path.join(TEST_DATA_DIR, \"images\") # Subdirectory for test images\n# Define paths for dummy data files within TEST_DATA_DIR\nTEST_VISION_FILE = os.path.join(TEST_DATA_DIR, \"test_vision.json\")\nTEST_SENSOR_FILE = os.path.join(TEST_DATA_DIR, \"test_sensors.json\")\nTEST_TEXT_FILE = os.path.join(TEST_DATA_DIR, \"test_text.json\")\nTEST_PAIRS_FILE = os.path.join(TEST_DATA_DIR, \"test_pairs.json\")\n# Define paths for AI model files within TEST_DATA_DIR\nTEST_TEMPORAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_model.json\")\nTEST_TEMPORAL_MEMORY_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_memory.json\")\nTEST_CEREBELLUM_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_cerebellum_model.json\")",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_VISION_FILE",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_VISION_FILE = os.path.join(TEST_DATA_DIR, \"test_vision.json\")\nTEST_SENSOR_FILE = os.path.join(TEST_DATA_DIR, \"test_sensors.json\")\nTEST_TEXT_FILE = os.path.join(TEST_DATA_DIR, \"test_text.json\")\nTEST_PAIRS_FILE = os.path.join(TEST_DATA_DIR, \"test_pairs.json\")\n# Define paths for AI model files within TEST_DATA_DIR\nTEST_TEMPORAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_model.json\")\nTEST_TEMPORAL_MEMORY_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_memory.json\")\nTEST_CEREBELLUM_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_cerebellum_model.json\")\nTEST_LIMBIC_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_limbic_model.weights.h5\")  # Keras convention\nTEST_OCCIPITAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_occipital_model.weights.h5\")  # Keras convention",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_SENSOR_FILE",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_SENSOR_FILE = os.path.join(TEST_DATA_DIR, \"test_sensors.json\")\nTEST_TEXT_FILE = os.path.join(TEST_DATA_DIR, \"test_text.json\")\nTEST_PAIRS_FILE = os.path.join(TEST_DATA_DIR, \"test_pairs.json\")\n# Define paths for AI model files within TEST_DATA_DIR\nTEST_TEMPORAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_model.json\")\nTEST_TEMPORAL_MEMORY_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_memory.json\")\nTEST_CEREBELLUM_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_cerebellum_model.json\")\nTEST_LIMBIC_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_limbic_model.weights.h5\")  # Keras convention\nTEST_OCCIPITAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_occipital_model.weights.h5\")  # Keras convention\nTEST_FRONTAL_MODEL_PATH = os.path.join(",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_TEXT_FILE",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_TEXT_FILE = os.path.join(TEST_DATA_DIR, \"test_text.json\")\nTEST_PAIRS_FILE = os.path.join(TEST_DATA_DIR, \"test_pairs.json\")\n# Define paths for AI model files within TEST_DATA_DIR\nTEST_TEMPORAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_model.json\")\nTEST_TEMPORAL_MEMORY_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_memory.json\")\nTEST_CEREBELLUM_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_cerebellum_model.json\")\nTEST_LIMBIC_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_limbic_model.weights.h5\")  # Keras convention\nTEST_OCCIPITAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_occipital_model.weights.h5\")  # Keras convention\nTEST_FRONTAL_MODEL_PATH = os.path.join(\n    TEST_DATA_DIR, \"test_frontal_model.weights.h5\"",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_PAIRS_FILE",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_PAIRS_FILE = os.path.join(TEST_DATA_DIR, \"test_pairs.json\")\n# Define paths for AI model files within TEST_DATA_DIR\nTEST_TEMPORAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_model.json\")\nTEST_TEMPORAL_MEMORY_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_memory.json\")\nTEST_CEREBELLUM_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_cerebellum_model.json\")\nTEST_LIMBIC_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_limbic_model.weights.h5\")  # Keras convention\nTEST_OCCIPITAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_occipital_model.weights.h5\")  # Keras convention\nTEST_FRONTAL_MODEL_PATH = os.path.join(\n    TEST_DATA_DIR, \"test_frontal_model.weights.h5\"\n)  # Keras convention",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_TEMPORAL_MODEL_PATH",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_TEMPORAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_model.json\")\nTEST_TEMPORAL_MEMORY_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_memory.json\")\nTEST_CEREBELLUM_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_cerebellum_model.json\")\nTEST_LIMBIC_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_limbic_model.weights.h5\")  # Keras convention\nTEST_OCCIPITAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_occipital_model.weights.h5\")  # Keras convention\nTEST_FRONTAL_MODEL_PATH = os.path.join(\n    TEST_DATA_DIR, \"test_frontal_model.weights.h5\"\n)  # Keras convention\nTEST_PARIETAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_parietal_model.json\") # Added for ParietalLobeAI\nclass TestDataLoading(unittest.TestCase):",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_TEMPORAL_MEMORY_PATH",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_TEMPORAL_MEMORY_PATH = os.path.join(TEST_DATA_DIR, \"test_temporal_memory.json\")\nTEST_CEREBELLUM_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_cerebellum_model.json\")\nTEST_LIMBIC_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_limbic_model.weights.h5\")  # Keras convention\nTEST_OCCIPITAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_occipital_model.weights.h5\")  # Keras convention\nTEST_FRONTAL_MODEL_PATH = os.path.join(\n    TEST_DATA_DIR, \"test_frontal_model.weights.h5\"\n)  # Keras convention\nTEST_PARIETAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_parietal_model.json\") # Added for ParietalLobeAI\nclass TestDataLoading(unittest.TestCase):\n    @classmethod",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_CEREBELLUM_MODEL_PATH",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_CEREBELLUM_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_cerebellum_model.json\")\nTEST_LIMBIC_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_limbic_model.weights.h5\")  # Keras convention\nTEST_OCCIPITAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_occipital_model.weights.h5\")  # Keras convention\nTEST_FRONTAL_MODEL_PATH = os.path.join(\n    TEST_DATA_DIR, \"test_frontal_model.weights.h5\"\n)  # Keras convention\nTEST_PARIETAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_parietal_model.json\") # Added for ParietalLobeAI\nclass TestDataLoading(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_LIMBIC_MODEL_PATH",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_LIMBIC_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_limbic_model.weights.h5\")  # Keras convention\nTEST_OCCIPITAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_occipital_model.weights.h5\")  # Keras convention\nTEST_FRONTAL_MODEL_PATH = os.path.join(\n    TEST_DATA_DIR, \"test_frontal_model.weights.h5\"\n)  # Keras convention\nTEST_PARIETAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_parietal_model.json\") # Added for ParietalLobeAI\nclass TestDataLoading(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_OCCIPITAL_MODEL_PATH",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_OCCIPITAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_occipital_model.weights.h5\")  # Keras convention\nTEST_FRONTAL_MODEL_PATH = os.path.join(\n    TEST_DATA_DIR, \"test_frontal_model.weights.h5\"\n)  # Keras convention\nTEST_PARIETAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_parietal_model.json\") # Added for ParietalLobeAI\nclass TestDataLoading(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)\n        cls.vision_content = {\"image_paths\": [os.path.join(TEST_IMAGES_SUBDIR, \"img1.png\")]}",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_FRONTAL_MODEL_PATH",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_FRONTAL_MODEL_PATH = os.path.join(\n    TEST_DATA_DIR, \"test_frontal_model.weights.h5\"\n)  # Keras convention\nTEST_PARIETAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_parietal_model.json\") # Added for ParietalLobeAI\nclass TestDataLoading(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)\n        cls.vision_content = {\"image_paths\": [os.path.join(TEST_IMAGES_SUBDIR, \"img1.png\")]}\n        with open(TEST_VISION_FILE, 'w') as f:",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "TEST_PARIETAL_MODEL_PATH",
        "kind": 5,
        "importPath": "tests.test_ai_modules",
        "description": "tests.test_ai_modules",
        "peekOfCode": "TEST_PARIETAL_MODEL_PATH = os.path.join(TEST_DATA_DIR, \"test_parietal_model.json\") # Added for ParietalLobeAI\nclass TestDataLoading(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        os.makedirs(TEST_DATA_DIR, exist_ok=True)\n        cls.vision_content = {\"image_paths\": [os.path.join(TEST_IMAGES_SUBDIR, \"img1.png\")]}\n        with open(TEST_VISION_FILE, 'w') as f:\n            json.dump(cls.vision_content, f)\n        cls.sensor_content = [[1.0, 2.0], [3.0, 4.0]]\n        with open(TEST_SENSOR_FILE, 'w') as f:",
        "detail": "tests.test_ai_modules",
        "documentation": {}
    },
    {
        "label": "CerebellumAI",
        "kind": 6,
        "importPath": "cerebellum",
        "description": "cerebellum",
        "peekOfCode": "class CerebellumAI:\n    def __init__(self, model_path=\"data/cerebellum_model.json\"):\n        self.input_size = 10  # Sensor feedback\n        self.hidden_size = 20  # Size of the new hidden layer\n        self.output_size = 3  # Motor commands (e.g., scaled between -1 and 1)\n        self.learning_rate_learn = 0.01\n        self.learning_rate_consolidate = 0.005\n        # Weights will be initialized by load_model or _initialize_default_weights_biases\n        self.weights_input_hidden = None\n        self.bias_hidden = None",
        "detail": "cerebellum",
        "documentation": {}
    },
    {
        "label": "img1",
        "kind": 5,
        "importPath": "default_image",
        "description": "default_image",
        "peekOfCode": "img1 = Image.new(\"RGB\", (50, 50), color=\"red\")\nimg1.save(\"data/images/image1.png\")\n# Create image2.png (blue square)\nimg2 = Image.new(\"RGB\", (50, 50), color=\"blue\")\nimg2.save(\"data/images/image2.png\")\n# Create default_image.png (gray square)\ndefault_img = Image.new(\"RGB\", (32, 32), color=\"gray\")\ndefault_img.save(\"data/images/default_image.png\")\nprint(\"images created successfully in data/images/\")",
        "detail": "default_image",
        "documentation": {}
    },
    {
        "label": "img2",
        "kind": 5,
        "importPath": "default_image",
        "description": "default_image",
        "peekOfCode": "img2 = Image.new(\"RGB\", (50, 50), color=\"blue\")\nimg2.save(\"data/images/image2.png\")\n# Create default_image.png (gray square)\ndefault_img = Image.new(\"RGB\", (32, 32), color=\"gray\")\ndefault_img.save(\"data/images/default_image.png\")\nprint(\"images created successfully in data/images/\")",
        "detail": "default_image",
        "documentation": {}
    },
    {
        "label": "default_img",
        "kind": 5,
        "importPath": "default_image",
        "description": "default_image",
        "peekOfCode": "default_img = Image.new(\"RGB\", (32, 32), color=\"gray\")\ndefault_img.save(\"data/images/default_image.png\")\nprint(\"images created successfully in data/images/\")",
        "detail": "default_image",
        "documentation": {}
    },
    {
        "label": "FrontalLobeAI",
        "kind": 6,
        "importPath": "frontal",
        "description": "frontal",
        "peekOfCode": "class FrontalLobeAI:\n    def __init__(\n        self, input_size=18, output_size=5, model_path=\"data/frontal_model.weights.h5\", replay_batch_size=32\n    ):\n        self.input_size = input_size  # State size\n        self.output_size = output_size  # Action size\n        # DQN Parameters\n        self.learning_rate_dqn = 0.001\n        self.discount_factor_gamma = 0.95\n        self.replay_buffer_size = 10000",
        "detail": "frontal",
        "documentation": {}
    },
    {
        "label": "parse_json_list",
        "kind": 2,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "def parse_json_list(json_string, default_value, expected_type=list):\n    if not json_string: # If string is empty or None\n        return default_value\n    try:\n        parsed = json.loads(json_string)\n        if isinstance(parsed, expected_type):\n            return parsed\n        else:\n            print(f\"Warning: Parsed JSON '{json_string}' is not of type {expected_type}. Got {type(parsed)}. Using default.\")\n            return default_value",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "run_ai_day_interface",
        "kind": 2,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "def run_ai_day_interface(\n    vision_input_path,\n    text_data,\n    expected_response,\n    sensor_data_str,\n    action_reward,\n    spatial_error_str,\n    memory_target,\n    vision_label,\n    motor_command_str, # This is feedback emotion_label, not the predicted one",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "train_on_book",
        "kind": 2,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "def train_on_book(book_file):\n    old_stdout = sys.stdout\n    sys.stdout = captured_output = StringIO()\n    try:\n        if book_file is None or not os.path.exists(book_file):\n            print(\"No book file provided or file does not exist.\")\n            sys.stdout = old_stdout\n            return {\"result\": \"No file provided.\"}, captured_output.getvalue()\n        with open(book_file, 'r', encoding='utf-8') as f:\n            text = f.read()",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "list_learned_qa_gui",
        "kind": 2,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "def list_learned_qa_gui():\n    qa_list = []\n    for idx, seq in enumerate(coordinator.temporal.memory_db):\n        for q, a in seq:\n            qa_list.append({\"Q\": q, \"A\": a})\n    if not qa_list:\n        return [{\"Q\": \"No Q&A pairs learned yet.\", \"A\": \"\"}]\n    return qa_list\ndef qa_list_gui():\n    return list_learned_qa_gui()",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "qa_list_gui",
        "kind": 2,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "def qa_list_gui():\n    return list_learned_qa_gui()\n# --- Functions for \"Generate Example\" buttons ---\ndef get_example_sensor_data():\n    example_data = np.random.rand(coordinator.parietal.input_size).tolist()\n    return json.dumps([round(x, 3) for x in example_data])\ndef get_example_spatial_error():\n    example_data = np.random.rand(coordinator.parietal.output_size).tolist()\n    return json.dumps([round(x, 3) for x in example_data])\ndef get_example_motor_command():",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "get_example_sensor_data",
        "kind": 2,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "def get_example_sensor_data():\n    example_data = np.random.rand(coordinator.parietal.input_size).tolist()\n    return json.dumps([round(x, 3) for x in example_data])\ndef get_example_spatial_error():\n    example_data = np.random.rand(coordinator.parietal.output_size).tolist()\n    return json.dumps([round(x, 3) for x in example_data])\ndef get_example_motor_command():\n    example_data = np.random.rand(coordinator.cerebellum.output_size).tolist()\n    return json.dumps([round(x, 3) for x in example_data])\n# Define Gradio Inputs",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "get_example_spatial_error",
        "kind": 2,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "def get_example_spatial_error():\n    example_data = np.random.rand(coordinator.parietal.output_size).tolist()\n    return json.dumps([round(x, 3) for x in example_data])\ndef get_example_motor_command():\n    example_data = np.random.rand(coordinator.cerebellum.output_size).tolist()\n    return json.dumps([round(x, 3) for x in example_data])\n# Define Gradio Inputs\nvision_input_path_component = gr.Image(type=\"filepath\", label=\"Vision Input Image\", value=DEFAULT_IMAGE_PATH,\n                                       ) # info=\"Upload an image for the AI to 'see'.\"\ntext_data_component = gr.Textbox(label=\"Text Data (Sentence, Question, or Paragraph)\",",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "get_example_motor_command",
        "kind": 2,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "def get_example_motor_command():\n    example_data = np.random.rand(coordinator.cerebellum.output_size).tolist()\n    return json.dumps([round(x, 3) for x in example_data])\n# Define Gradio Inputs\nvision_input_path_component = gr.Image(type=\"filepath\", label=\"Vision Input Image\", value=DEFAULT_IMAGE_PATH,\n                                       ) # info=\"Upload an image for the AI to 'see'.\"\ntext_data_component = gr.Textbox(label=\"Text Data (Sentence, Question, or Paragraph)\",\n                                 value=\"A small red block is on the table.\", lines=4,\n                                 info=\"Main textual input for the AI. Can be a statement, question, or part of a narrative.\")\nexpected_response_component = gr.Textbox(label=\"Expected Response (Answer, Next Sentence, or Target Text)\",",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "project_root",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "project_root = os.path.abspath(os.path.dirname(__file__))\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n# Global instance of BrainCoordinator\n# This ensures the AI models retain their state across Gradio interactions\nprint(\"Initializing BrainCoordinator for Gradio GUI...\")\ncoordinator = BrainCoordinator()\nprint(\"BrainCoordinator initialized.\")\n# Dynamically create emotion names\nEMOTION_NAMES = [f\"Emotion {i}\" for i in range(coordinator.limbic.output_size)]",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "coordinator",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "coordinator = BrainCoordinator()\nprint(\"BrainCoordinator initialized.\")\n# Dynamically create emotion names\nEMOTION_NAMES = [f\"Emotion {i}\" for i in range(coordinator.limbic.output_size)]\nif coordinator.limbic.output_size == 3: # Example specific names if size is 3\n    EMOTION_NAMES = [\"Positive\", \"Neutral\", \"Negative\"] # Or Happy, Neutral, Sad etc.\nelif coordinator.limbic.output_size == 0: # Handle edge case\n    EMOTION_NAMES = []\n# Helper to parse JSON string input for lists\ndef parse_json_list(json_string, default_value, expected_type=list):",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "EMOTION_NAMES",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "EMOTION_NAMES = [f\"Emotion {i}\" for i in range(coordinator.limbic.output_size)]\nif coordinator.limbic.output_size == 3: # Example specific names if size is 3\n    EMOTION_NAMES = [\"Positive\", \"Neutral\", \"Negative\"] # Or Happy, Neutral, Sad etc.\nelif coordinator.limbic.output_size == 0: # Handle edge case\n    EMOTION_NAMES = []\n# Helper to parse JSON string input for lists\ndef parse_json_list(json_string, default_value, expected_type=list):\n    if not json_string: # If string is empty or None\n        return default_value\n    try:",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "vision_input_path_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "vision_input_path_component = gr.Image(type=\"filepath\", label=\"Vision Input Image\", value=DEFAULT_IMAGE_PATH,\n                                       ) # info=\"Upload an image for the AI to 'see'.\"\ntext_data_component = gr.Textbox(label=\"Text Data (Sentence, Question, or Paragraph)\",\n                                 value=\"A small red block is on the table.\", lines=4,\n                                 info=\"Main textual input for the AI. Can be a statement, question, or part of a narrative.\")\nexpected_response_component = gr.Textbox(label=\"Expected Response (Answer, Next Sentence, or Target Text)\",\n                                         value=\"The block is red.\", lines=4,\n                                         info=\"If Text Data is a question, this is the answer. If a statement, this could be the next logical sentence.\")\nsensor_data_component = gr.Textbox(\n    label=\"Sensor Data\",",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "text_data_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "text_data_component = gr.Textbox(label=\"Text Data (Sentence, Question, or Paragraph)\",\n                                 value=\"A small red block is on the table.\", lines=4,\n                                 info=\"Main textual input for the AI. Can be a statement, question, or part of a narrative.\")\nexpected_response_component = gr.Textbox(label=\"Expected Response (Answer, Next Sentence, or Target Text)\",\n                                         value=\"The block is red.\", lines=4,\n                                         info=\"If Text Data is a question, this is the answer. If a statement, this could be the next logical sentence.\")\nsensor_data_component = gr.Textbox(\n    label=\"Sensor Data\",\n    placeholder=f\"e.g., JSON list of {coordinator.parietal.input_size} floats like [0.1, 0.2, ...].\",\n    lines=2,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "expected_response_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "expected_response_component = gr.Textbox(label=\"Expected Response (Answer, Next Sentence, or Target Text)\",\n                                         value=\"The block is red.\", lines=4,\n                                         info=\"If Text Data is a question, this is the answer. If a statement, this could be the next logical sentence.\")\nsensor_data_component = gr.Textbox(\n    label=\"Sensor Data\",\n    placeholder=f\"e.g., JSON list of {coordinator.parietal.input_size} floats like [0.1, 0.2, ...].\",\n    lines=2,\n    info=\"Simulated sensory readings. Click 'Generate Example' or leave blank for random.\"\n)\n# Button for sensor data example",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "sensor_data_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "sensor_data_component = gr.Textbox(\n    label=\"Sensor Data\",\n    placeholder=f\"e.g., JSON list of {coordinator.parietal.input_size} floats like [0.1, 0.2, ...].\",\n    lines=2,\n    info=\"Simulated sensory readings. Click 'Generate Example' or leave blank for random.\"\n)\n# Button for sensor data example\ngenerate_sensor_example_button = gr.Button(\"Generate Example Sensor Data\", size=\"sm\", variant=\"secondary\")\nfeedback_action_reward_component = gr.Radio([-1, 0, 1], label=\"Feedback: Action Reward\", value=0, type=\"value\",\n                                            info=\"Reward signal for the AI's last general action (-1: penalty, 0: neutral, 1: reward).\")",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "generate_sensor_example_button",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "generate_sensor_example_button = gr.Button(\"Generate Example Sensor Data\", size=\"sm\", variant=\"secondary\")\nfeedback_action_reward_component = gr.Radio([-1, 0, 1], label=\"Feedback: Action Reward\", value=0, type=\"value\",\n                                            info=\"Reward signal for the AI's last general action (-1: penalty, 0: neutral, 1: reward).\")\nfeedback_spatial_error_component = gr.Textbox(\n    label=\"Feedback: Spatial Error\",\n    placeholder=f\"e.g., JSON list of {coordinator.parietal.output_size} floats like [0.0, 0.1, -0.05].\",\n    lines=1,\n    info=\"Error signal for spatial awareness/prediction. Click 'Generate Example' or leave blank for random.\"\n)\ngenerate_spatial_example_button = gr.Button(\"Generate Example Spatial Error\", size=\"sm\", variant=\"secondary\")",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "feedback_action_reward_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "feedback_action_reward_component = gr.Radio([-1, 0, 1], label=\"Feedback: Action Reward\", value=0, type=\"value\",\n                                            info=\"Reward signal for the AI's last general action (-1: penalty, 0: neutral, 1: reward).\")\nfeedback_spatial_error_component = gr.Textbox(\n    label=\"Feedback: Spatial Error\",\n    placeholder=f\"e.g., JSON list of {coordinator.parietal.output_size} floats like [0.0, 0.1, -0.05].\",\n    lines=1,\n    info=\"Error signal for spatial awareness/prediction. Click 'Generate Example' or leave blank for random.\"\n)\ngenerate_spatial_example_button = gr.Button(\"Generate Example Spatial Error\", size=\"sm\", variant=\"secondary\")\nfeedback_memory_target_component = gr.Textbox(label=\"Feedback: Memory Target Text\", lines=2,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "feedback_spatial_error_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "feedback_spatial_error_component = gr.Textbox(\n    label=\"Feedback: Spatial Error\",\n    placeholder=f\"e.g., JSON list of {coordinator.parietal.output_size} floats like [0.0, 0.1, -0.05].\",\n    lines=1,\n    info=\"Error signal for spatial awareness/prediction. Click 'Generate Example' or leave blank for random.\"\n)\ngenerate_spatial_example_button = gr.Button(\"Generate Example Spatial Error\", size=\"sm\", variant=\"secondary\")\nfeedback_memory_target_component = gr.Textbox(label=\"Feedback: Memory Target Text\", lines=2,\n                                              placeholder=\"Text AI should associate with the input Text Data. If blank, uses input Text Data itself.\",\n                                              info=\"Specific text the AI should learn/memorize in relation to the main Text Data.\")",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "generate_spatial_example_button",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "generate_spatial_example_button = gr.Button(\"Generate Example Spatial Error\", size=\"sm\", variant=\"secondary\")\nfeedback_memory_target_component = gr.Textbox(label=\"Feedback: Memory Target Text\", lines=2,\n                                              placeholder=\"Text AI should associate with the input Text Data. If blank, uses input Text Data itself.\",\n                                              info=\"Specific text the AI should learn/memorize in relation to the main Text Data.\")\nfeedback_vision_label_component = gr.Number(label=\"Feedback: True Vision Label (int)\", value=0, precision=0,\n                                            info=f\"Correct classification label for the vision input (0 to {coordinator.occipital.output_size - 1}).\")\nfeedback_motor_command_component = gr.Textbox(\n    label=\"Feedback: True Motor Command\",\n    placeholder=f\"e.g., JSON list of {coordinator.cerebellum.output_size} floats like [0.5, -0.2, 0.0].\",\n    lines=1,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "feedback_memory_target_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "feedback_memory_target_component = gr.Textbox(label=\"Feedback: Memory Target Text\", lines=2,\n                                              placeholder=\"Text AI should associate with the input Text Data. If blank, uses input Text Data itself.\",\n                                              info=\"Specific text the AI should learn/memorize in relation to the main Text Data.\")\nfeedback_vision_label_component = gr.Number(label=\"Feedback: True Vision Label (int)\", value=0, precision=0,\n                                            info=f\"Correct classification label for the vision input (0 to {coordinator.occipital.output_size - 1}).\")\nfeedback_motor_command_component = gr.Textbox(\n    label=\"Feedback: True Motor Command\",\n    placeholder=f\"e.g., JSON list of {coordinator.cerebellum.output_size} floats like [0.5, -0.2, 0.0].\",\n    lines=1,\n    info=\"Correct motor command sequence. Click 'Generate Example' or leave blank for random.\"",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "feedback_vision_label_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "feedback_vision_label_component = gr.Number(label=\"Feedback: True Vision Label (int)\", value=0, precision=0,\n                                            info=f\"Correct classification label for the vision input (0 to {coordinator.occipital.output_size - 1}).\")\nfeedback_motor_command_component = gr.Textbox(\n    label=\"Feedback: True Motor Command\",\n    placeholder=f\"e.g., JSON list of {coordinator.cerebellum.output_size} floats like [0.5, -0.2, 0.0].\",\n    lines=1,\n    info=\"Correct motor command sequence. Click 'Generate Example' or leave blank for random.\"\n)\ngenerate_motor_example_button = gr.Button(\"Generate Example Motor Command\", size=\"sm\", variant=\"secondary\")\nfeedback_emotion_label_component = gr.Number(label=\"Feedback: True Emotion Label (int)\", value=0, precision=0,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "feedback_motor_command_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "feedback_motor_command_component = gr.Textbox(\n    label=\"Feedback: True Motor Command\",\n    placeholder=f\"e.g., JSON list of {coordinator.cerebellum.output_size} floats like [0.5, -0.2, 0.0].\",\n    lines=1,\n    info=\"Correct motor command sequence. Click 'Generate Example' or leave blank for random.\"\n)\ngenerate_motor_example_button = gr.Button(\"Generate Example Motor Command\", size=\"sm\", variant=\"secondary\")\nfeedback_emotion_label_component = gr.Number(label=\"Feedback: True Emotion Label (int)\", value=0, precision=0,\n                                             info=f\"Correct emotion label for the current context (0 to {coordinator.limbic.output_size - 1}).\")\ncorrection_component = gr.Textbox(label=\"Correct AI Output (Reinforcement)\", value=\"\", lines=3,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "generate_motor_example_button",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "generate_motor_example_button = gr.Button(\"Generate Example Motor Command\", size=\"sm\", variant=\"secondary\")\nfeedback_emotion_label_component = gr.Number(label=\"Feedback: True Emotion Label (int)\", value=0, precision=0,\n                                             info=f\"Correct emotion label for the current context (0 to {coordinator.limbic.output_size - 1}).\")\ncorrection_component = gr.Textbox(label=\"Correct AI Output (Reinforcement)\", value=\"\", lines=3,\n                                  placeholder=\"If the AI's textual response was incorrect, enter the correct response here to reinforce it.\",\n                                  info=\"Provide the correct text if the AI's generated response (from memory) was wrong.\")\naudio_input_component = gr.Audio(type=\"filepath\", label=\"Audio Input (Experimental)\",\n                                 # info=\"Upload an audio file. Currently logged but not used for training.\" # Pylance: No parameter named \"info\"\n                                 )\n# Add Gradio file upload and button for book training",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "feedback_emotion_label_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "feedback_emotion_label_component = gr.Number(label=\"Feedback: True Emotion Label (int)\", value=0, precision=0,\n                                             info=f\"Correct emotion label for the current context (0 to {coordinator.limbic.output_size - 1}).\")\ncorrection_component = gr.Textbox(label=\"Correct AI Output (Reinforcement)\", value=\"\", lines=3,\n                                  placeholder=\"If the AI's textual response was incorrect, enter the correct response here to reinforce it.\",\n                                  info=\"Provide the correct text if the AI's generated response (from memory) was wrong.\")\naudio_input_component = gr.Audio(type=\"filepath\", label=\"Audio Input (Experimental)\",\n                                 # info=\"Upload an audio file. Currently logged but not used for training.\" # Pylance: No parameter named \"info\"\n                                 )\n# Add Gradio file upload and button for book training\nbook_file_component = gr.File(label=\"Upload Book (Text File)\")",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "correction_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "correction_component = gr.Textbox(label=\"Correct AI Output (Reinforcement)\", value=\"\", lines=3,\n                                  placeholder=\"If the AI's textual response was incorrect, enter the correct response here to reinforce it.\",\n                                  info=\"Provide the correct text if the AI's generated response (from memory) was wrong.\")\naudio_input_component = gr.Audio(type=\"filepath\", label=\"Audio Input (Experimental)\",\n                                 # info=\"Upload an audio file. Currently logged but not used for training.\" # Pylance: No parameter named \"info\"\n                                 )\n# Add Gradio file upload and button for book training\nbook_file_component = gr.File(label=\"Upload Book (Text File)\")\ntrain_book_button = gr.Button(\"Train AI on Book\", variant=\"secondary\")\nbook_train_result_component = gr.JSON(label=\"Book Training Result\")",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "audio_input_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "audio_input_component = gr.Audio(type=\"filepath\", label=\"Audio Input (Experimental)\",\n                                 # info=\"Upload an audio file. Currently logged but not used for training.\" # Pylance: No parameter named \"info\"\n                                 )\n# Add Gradio file upload and button for book training\nbook_file_component = gr.File(label=\"Upload Book (Text File)\")\ntrain_book_button = gr.Button(\"Train AI on Book\", variant=\"secondary\")\nbook_train_result_component = gr.JSON(label=\"Book Training Result\")\nbook_train_log_component = gr.Textbox(label=\"Book Training Log\", lines=10, interactive=False, autoscroll=True)\n# Define Gradio Outputs\nresults_component = gr.JSON(label=\"Processing Results (Raw)\")",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "book_file_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "book_file_component = gr.File(label=\"Upload Book (Text File)\")\ntrain_book_button = gr.Button(\"Train AI on Book\", variant=\"secondary\")\nbook_train_result_component = gr.JSON(label=\"Book Training Result\")\nbook_train_log_component = gr.Textbox(label=\"Book Training Log\", lines=10, interactive=False, autoscroll=True)\n# Define Gradio Outputs\nresults_component = gr.JSON(label=\"Processing Results (Raw)\")\nlog_component = gr.Textbox(label=\"Log Output\", lines=20, interactive=False, autoscroll=True)\nemotion_plot_component = gr.BarPlot(label=\"Predicted Emotion Probabilities\",\n                                    # info=\"Visualization of the AI's predicted emotional state probabilities.\" # Pylance: No parameter named \"info\"\n                                    )",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "train_book_button",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "train_book_button = gr.Button(\"Train AI on Book\", variant=\"secondary\")\nbook_train_result_component = gr.JSON(label=\"Book Training Result\")\nbook_train_log_component = gr.Textbox(label=\"Book Training Log\", lines=10, interactive=False, autoscroll=True)\n# Define Gradio Outputs\nresults_component = gr.JSON(label=\"Processing Results (Raw)\")\nlog_component = gr.Textbox(label=\"Log Output\", lines=20, interactive=False, autoscroll=True)\nemotion_plot_component = gr.BarPlot(label=\"Predicted Emotion Probabilities\",\n                                    # info=\"Visualization of the AI's predicted emotional state probabilities.\" # Pylance: No parameter named \"info\"\n                                    )\n# Add Q&A memory display components",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "book_train_result_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "book_train_result_component = gr.JSON(label=\"Book Training Result\")\nbook_train_log_component = gr.Textbox(label=\"Book Training Log\", lines=10, interactive=False, autoscroll=True)\n# Define Gradio Outputs\nresults_component = gr.JSON(label=\"Processing Results (Raw)\")\nlog_component = gr.Textbox(label=\"Log Output\", lines=20, interactive=False, autoscroll=True)\nemotion_plot_component = gr.BarPlot(label=\"Predicted Emotion Probabilities\",\n                                    # info=\"Visualization of the AI's predicted emotional state probabilities.\" # Pylance: No parameter named \"info\"\n                                    )\n# Add Q&A memory display components\nqa_list_component = gr.Dataframe(headers=[\"Q\", \"A\"], label=\"Learned Q&A Pairs\", interactive=False)",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "book_train_log_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "book_train_log_component = gr.Textbox(label=\"Book Training Log\", lines=10, interactive=False, autoscroll=True)\n# Define Gradio Outputs\nresults_component = gr.JSON(label=\"Processing Results (Raw)\")\nlog_component = gr.Textbox(label=\"Log Output\", lines=20, interactive=False, autoscroll=True)\nemotion_plot_component = gr.BarPlot(label=\"Predicted Emotion Probabilities\",\n                                    # info=\"Visualization of the AI's predicted emotional state probabilities.\" # Pylance: No parameter named \"info\"\n                                    )\n# Add Q&A memory display components\nqa_list_component = gr.Dataframe(headers=[\"Q\", \"A\"], label=\"Learned Q&A Pairs\", interactive=False)\nshow_qa_button = gr.Button(\"Show All Learned Q&A Pairs\", variant=\"secondary\")",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "results_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "results_component = gr.JSON(label=\"Processing Results (Raw)\")\nlog_component = gr.Textbox(label=\"Log Output\", lines=20, interactive=False, autoscroll=True)\nemotion_plot_component = gr.BarPlot(label=\"Predicted Emotion Probabilities\",\n                                    # info=\"Visualization of the AI's predicted emotional state probabilities.\" # Pylance: No parameter named \"info\"\n                                    )\n# Add Q&A memory display components\nqa_list_component = gr.Dataframe(headers=[\"Q\", \"A\"], label=\"Learned Q&A Pairs\", interactive=False)\nshow_qa_button = gr.Button(\"Show All Learned Q&A Pairs\", variant=\"secondary\")\ninputs_list = [\n    vision_input_path_component,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "log_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "log_component = gr.Textbox(label=\"Log Output\", lines=20, interactive=False, autoscroll=True)\nemotion_plot_component = gr.BarPlot(label=\"Predicted Emotion Probabilities\",\n                                    # info=\"Visualization of the AI's predicted emotional state probabilities.\" # Pylance: No parameter named \"info\"\n                                    )\n# Add Q&A memory display components\nqa_list_component = gr.Dataframe(headers=[\"Q\", \"A\"], label=\"Learned Q&A Pairs\", interactive=False)\nshow_qa_button = gr.Button(\"Show All Learned Q&A Pairs\", variant=\"secondary\")\ninputs_list = [\n    vision_input_path_component,\n    text_data_component,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "emotion_plot_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "emotion_plot_component = gr.BarPlot(label=\"Predicted Emotion Probabilities\",\n                                    # info=\"Visualization of the AI's predicted emotional state probabilities.\" # Pylance: No parameter named \"info\"\n                                    )\n# Add Q&A memory display components\nqa_list_component = gr.Dataframe(headers=[\"Q\", \"A\"], label=\"Learned Q&A Pairs\", interactive=False)\nshow_qa_button = gr.Button(\"Show All Learned Q&A Pairs\", variant=\"secondary\")\ninputs_list = [\n    vision_input_path_component,\n    text_data_component,\n    expected_response_component,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "qa_list_component",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "qa_list_component = gr.Dataframe(headers=[\"Q\", \"A\"], label=\"Learned Q&A Pairs\", interactive=False)\nshow_qa_button = gr.Button(\"Show All Learned Q&A Pairs\", variant=\"secondary\")\ninputs_list = [\n    vision_input_path_component,\n    text_data_component,\n    expected_response_component,\n    sensor_data_component,\n    feedback_action_reward_component,\n    feedback_spatial_error_component,\n    feedback_memory_target_component,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "show_qa_button",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "show_qa_button = gr.Button(\"Show All Learned Q&A Pairs\", variant=\"secondary\")\ninputs_list = [\n    vision_input_path_component,\n    text_data_component,\n    expected_response_component,\n    sensor_data_component,\n    feedback_action_reward_component,\n    feedback_spatial_error_component,\n    feedback_memory_target_component,\n    feedback_vision_label_component,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "inputs_list",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "inputs_list = [\n    vision_input_path_component,\n    text_data_component,\n    expected_response_component,\n    sensor_data_component,\n    feedback_action_reward_component,\n    feedback_spatial_error_component,\n    feedback_memory_target_component,\n    feedback_vision_label_component,\n    feedback_motor_command_component,",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "outputs_list",
        "kind": 5,
        "importPath": "gui",
        "description": "gui",
        "peekOfCode": "outputs_list = [results_component, log_component, emotion_plot_component] # Added emotion_plot_component\nwith gr.Blocks(title=\"Baby AI Interactive Simulation\", theme=\"soft\") as demo: # Changed to string theme name\n    gr.Markdown(\"# 🧠 Baby AI Interactive Simulation\")\n    gr.Markdown(\"Interact with the AI by providing inputs for a 'day' of experience and observe its learning. All AI model weights are saved after each day's consolidation. Use the tabs below to navigate different interaction modes.\")\n    with gr.Tabs():\n        with gr.TabItem(\"☀️ Daily Interaction & Learning\"):\n            gr.Markdown(\"## Provide Daily Inputs and Feedback\")\n            gr.Markdown(\"Configure the AI's experience for one 'day', provide feedback, and observe the results.\")\n            with gr.Row():\n                with gr.Column(scale=2):",
        "detail": "gui",
        "documentation": {}
    },
    {
        "label": "LimbicSystemAI",
        "kind": 6,
        "importPath": "limbic",
        "description": "limbic",
        "peekOfCode": "class LimbicSystemAI:\n    def __init__(self, model_path=\"data/limbic_model.weights.h5\"):  # Updated extension\n        self.input_size = 10  # Processed output from TemporalLobeAI (size 10)\n        self.output_size = 3  # Emotion labels (e.g., happy, urgent, sad)\n        # Learning rate for the Keras optimizer\n        self.learning_rate_learn = 0.001  # Standard Keras learning rate\n        self.model_path = model_path\n        self.memory_path = self.model_path.replace(\n            \".weights.h5\", \"_memory.json\"\n        )  # Path for memory",
        "detail": "limbic",
        "documentation": {}
    },
    {
        "label": "BrainCoordinator",
        "kind": 6,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "class BrainCoordinator:\n    def __init__(self):\n        os.makedirs(DATA_DIR, exist_ok=True)\n        os.makedirs(os.path.join(DATA_DIR, \"images\"), exist_ok=True)\n        self.frontal = FrontalLobeAI()\n        self.parietal = ParietalLobeAI()\n        self.temporal = TemporalLobeAI()\n        self.occipital = OccipitalLobeAI()\n        self.cerebellum = CerebellumAI()\n        self.limbic = LimbicSystemAI()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "load_vision_data",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def load_vision_data(filepath=VISION_FILE):\n    if not os.path.exists(filepath):\n        print(f\"Warning: Vision data file not found at {filepath}. Returning empty list.\")\n        return []\n    try:\n        with open(filepath, \"r\") as f:\n            data = json.load(f)\n        # Expecting data to be a dict with \"image_paths\": [...]\n        if isinstance(data, dict) and \"image_paths\" in data and isinstance(data[\"image_paths\"], list):\n            return data[\"image_paths\"]",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "load_sensor_data",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def load_sensor_data(filepath=SENSOR_FILE):\n    if not os.path.exists(filepath):\n        print(\n            f\"Warning: Sensor data file not found at {filepath}. Returning empty list.\"\n        )\n        return []\n    try:\n        with open(filepath, \"r\") as f:\n            data = json.load(f)\n        return data",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "load_text_data",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def load_text_data(filepath=TEXT_FILE):\n    if not os.path.exists(filepath):\n        print(f\"Warning: Text data file not found at {filepath}. Returning empty list.\")\n        return []\n    try:\n        with open(filepath, \"r\") as f:\n            data = json.load(f)\n        if not isinstance(data, list): # Expecting a list of strings\n            print(f\"Error: Text data file {filepath} is not a list. Returning empty list.\")\n            return []",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "load_image_text_pairs",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def load_image_text_pairs(filepath=IMAGE_TEXT_PAIRS_FILE):\n    if not os.path.exists(filepath):\n        print(\n            f\"Error: Image-text pairs file not found at {filepath}. Returning empty list.\"\n        )\n        return []\n    try:\n        with open(filepath, \"r\") as f:\n            pairs = json.load(f)\n        if not isinstance(pairs, list):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "list_learned_qa",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def list_learned_qa(coordinator):\n    print(\"\\n--- Learned Q&A Pairs (Temporal Lobe) ---\")\n    if not coordinator.temporal.memory_db:\n        print(\"No Q&A pairs learned yet.\")\n        return\n    for idx, seq in enumerate(coordinator.temporal.memory_db):\n        for q, a in seq:\n            print(f\"{idx+1}. Q: {q}\\n   A: {a}\")\n    print(\"--- End of Q&A List ---\\n\")\ndef main():",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def main():\n    # Introductory Message\n    print(\"Welcome to the Interactive Baby AI Simulation!\\n\")\n    print(\"This simulation allows you to observe and interact with an AI as it learns.\")\n    print(\"You will have options to:\")\n    print(\"- Run the simulation for a specific number of 'days'.\")\n    print(\"- Run it indefinitely, providing input for each 'day'.\")\n    print(\"- For each 'day', you can let the AI process pre-scheduled data, or you can\")\n    print(\"  provide new data (images, text, feedback) to guide its learning.\\n\")\n    print(",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "train_on_book_cli",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def train_on_book_cli(book_file_path, coordinator):\n    if not os.path.exists(book_file_path):\n        print(f\"Book file '{book_file_path}' not found.\")\n        return\n    with open(book_file_path, 'r', encoding='utf-8') as f:\n        text = f.read()\n    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n    if len(paragraphs) < 2:\n        import re\n        paragraphs = re.split(r'(?<=[.!?]) +', text)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "DATA_DIR",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "DATA_DIR = \"data\"\nSENSOR_FILE = os.path.join(DATA_DIR, \"sensors.json\")\nVISION_FILE = os.path.join(DATA_DIR, \"vision.json\") # Added for vision data\nTEXT_FILE = os.path.join(DATA_DIR, \"text.json\")     # Added for text data\nIMAGE_TEXT_PAIRS_FILE = os.path.join(DATA_DIR, \"image_text_pairs.json\")\nDEFAULT_IMAGE_PATH = \"data/images/default_image.png\"\ndef load_vision_data(filepath=VISION_FILE):\n    if not os.path.exists(filepath):\n        print(f\"Warning: Vision data file not found at {filepath}. Returning empty list.\")\n        return []",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "SENSOR_FILE",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "SENSOR_FILE = os.path.join(DATA_DIR, \"sensors.json\")\nVISION_FILE = os.path.join(DATA_DIR, \"vision.json\") # Added for vision data\nTEXT_FILE = os.path.join(DATA_DIR, \"text.json\")     # Added for text data\nIMAGE_TEXT_PAIRS_FILE = os.path.join(DATA_DIR, \"image_text_pairs.json\")\nDEFAULT_IMAGE_PATH = \"data/images/default_image.png\"\ndef load_vision_data(filepath=VISION_FILE):\n    if not os.path.exists(filepath):\n        print(f\"Warning: Vision data file not found at {filepath}. Returning empty list.\")\n        return []\n    try:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "VISION_FILE",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "VISION_FILE = os.path.join(DATA_DIR, \"vision.json\") # Added for vision data\nTEXT_FILE = os.path.join(DATA_DIR, \"text.json\")     # Added for text data\nIMAGE_TEXT_PAIRS_FILE = os.path.join(DATA_DIR, \"image_text_pairs.json\")\nDEFAULT_IMAGE_PATH = \"data/images/default_image.png\"\ndef load_vision_data(filepath=VISION_FILE):\n    if not os.path.exists(filepath):\n        print(f\"Warning: Vision data file not found at {filepath}. Returning empty list.\")\n        return []\n    try:\n        with open(filepath, \"r\") as f:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "TEXT_FILE",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "TEXT_FILE = os.path.join(DATA_DIR, \"text.json\")     # Added for text data\nIMAGE_TEXT_PAIRS_FILE = os.path.join(DATA_DIR, \"image_text_pairs.json\")\nDEFAULT_IMAGE_PATH = \"data/images/default_image.png\"\ndef load_vision_data(filepath=VISION_FILE):\n    if not os.path.exists(filepath):\n        print(f\"Warning: Vision data file not found at {filepath}. Returning empty list.\")\n        return []\n    try:\n        with open(filepath, \"r\") as f:\n            data = json.load(f)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "IMAGE_TEXT_PAIRS_FILE",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "IMAGE_TEXT_PAIRS_FILE = os.path.join(DATA_DIR, \"image_text_pairs.json\")\nDEFAULT_IMAGE_PATH = \"data/images/default_image.png\"\ndef load_vision_data(filepath=VISION_FILE):\n    if not os.path.exists(filepath):\n        print(f\"Warning: Vision data file not found at {filepath}. Returning empty list.\")\n        return []\n    try:\n        with open(filepath, \"r\") as f:\n            data = json.load(f)\n        # Expecting data to be a dict with \"image_paths\": [...]",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "DEFAULT_IMAGE_PATH",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "DEFAULT_IMAGE_PATH = \"data/images/default_image.png\"\ndef load_vision_data(filepath=VISION_FILE):\n    if not os.path.exists(filepath):\n        print(f\"Warning: Vision data file not found at {filepath}. Returning empty list.\")\n        return []\n    try:\n        with open(filepath, \"r\") as f:\n            data = json.load(f)\n        # Expecting data to be a dict with \"image_paths\": [...]\n        if isinstance(data, dict) and \"image_paths\" in data and isinstance(data[\"image_paths\"], list):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "OccipitalLobeAI",
        "kind": 6,
        "importPath": "occipital",
        "description": "occipital",
        "peekOfCode": "class OccipitalLobeAI:\n    def __init__(\n        self, model_path=\"data/occipital_model.weights.h5\"\n    ):  # Changed extension\n        self.input_shape = (64, 64, 3)  # Height, Width, Channels (color images)\n        self.output_size = 5  # Number of object labels/classes\n        self.model_path = model_path\n        self.memory = deque(maxlen=100) # Store up to 100 recent experiences\n        self.consolidation_batch_size = 16 # Batch size for consolidation training\n        self.model = self._build_model()",
        "detail": "occipital",
        "documentation": {}
    },
    {
        "label": "ParietalLobeAI",
        "kind": 6,
        "importPath": "parietal",
        "description": "parietal",
        "peekOfCode": "class ParietalLobeAI:\n    def __init__(self, model_path=\"data/parietal_model.json\"):\n        self.input_size = 20  # Sensory data (e.g., sensor readings)\n        self.hidden_size = 25  # Size of the new hidden layer\n        self.output_size = (\n            3  # Spatial coordinates (e.g., x, y, z error or target position)\n        )\n        # Learning rates\n        self.learning_rate_learn = 0.01\n        self.learning_rate_consolidate = 0.005",
        "detail": "parietal",
        "documentation": {}
    },
    {
        "label": "TemporalLobeAI",
        "kind": 6,
        "importPath": "temporal",
        "description": "temporal",
        "peekOfCode": "class TemporalLobeAI:\n    def __init__(\n        self,\n        model_path=\"data/temporal_model.json\",\n        memory_path=\"data/temporal_memory.json\",\n    ):\n        self.input_size = 15\n        self.output_size = 10  # Dimension of text embeddings\n        self.visual_output_size = 5\n        self.text_hidden_size = 32",
        "detail": "temporal",
        "documentation": {}
    },
    {
        "label": "softmax",
        "kind": 2,
        "importPath": "temporal",
        "description": "temporal",
        "peekOfCode": "def softmax(x):\n    if x.ndim == 1:\n        e_x = np.exp(x - np.max(x))\n        return e_x / np.sum(e_x)\n    else:\n        e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n        return e_x / np.sum(e_x, axis=-1, keepdims=True)\nclass TemporalLobeAI:\n    def __init__(\n        self,",
        "detail": "temporal",
        "documentation": {}
    }
]